# 妙想

## 软件打招呼

* 您好我对贵司的XXXX很感兴趣，以下是我的基本情况：我硕士毕业于北京理工大学，有3年以上Java开发经验，熟练掌握如Java，spring boot，MongoDB，Redis，kafka，等后端技术栈，和git，elk，grafana，cicd等项目管理工具。有大型项目开发和管理经验，主导过大模型agent开发落地，有性能调优经验，有优秀的持续学习能力和技术落地能力。期待您的回复。

## 自我介绍

* 在上一份工作中，我主要参与主导了大模型智能助手项目的开发，实现了agent任务规划，执行，流式输出，记录保存的全流程，这与公司的岗位要求非常契合。其次我还参与了智能在线客服项目，将原项目的性能进行了优化；同时我还参与了资讯推荐接口的算法改进项目，主导了clickhouse数据库在组内的落地，日均处理4000W日志数据；
* 我熟练掌握如Java，spring boot，MongoDB，Redis，kafka，等后端技术栈，和git，elk，grafana，cicd等项目管理工具。有大型项目开发和管理经验，在前司获得S绩效，23年被评为公司年度优秀员工。此外还获得了软考中级软件设计师认证，个人独立全栈开发微信小程序，有出色的持续学习能力和技术落地能力。以上就是我的基本情况，谢谢；

## 项目中的难点

* 项目中的难点主要是agent体系的开发
* ReAct：reasoning and acting。由大模型思考，分析解决问题需要的步骤，再按顺序执行这些步骤，知道任务完成，最后由大模型返回最终结果；

1. 工具规范定义：根据项目需要提供的能力，接入对应的工具，也就是公司内部的各个接口。统一定义所有工具的输入输出，利用适配器模式，对各个工具进行适配。
2. agent协议定义：和算法约定agent的输入输出格式，主要是如何从agent的输出中解析任务以及参数，最终项目中通过prompt向agent提供任务名称，工具能力等信息，由agent模型输出json格式的文本，后续程序进行解析。
3. agent任务拆解的不确定性：前期使用GPT及公司自研模型，都有输出格式错误，导致解析失败，导致无法进行后续任务执行。为了优化模型拆分效果，算法团队针对agent任务拆分专门训练了agent模型，在训练数据中加入了agent拆分相关的数据，规范agent拆分的格式和准确性。并且为了解析的宽容度，没有让模型以整体JSON输出，因为整体JSON，只要有一个位置格式错误，就无法反序列化成功。项目中实际的设计是，以字符串格式输出，每个任务间由特殊符号分割，每个单一任务以JSON形式给出。这样在某一处位置出错时，不会影响其他任务的解析，在多个任务时，可以丢弃单个任务，其他任务正常执行，增加容错性；
4. agent任务参数识别：通用的做法是，给大模型的输入提供工具的参数格式，由大模型给出调用工具所需的参数，但是实际使用中是不现实的，因为工具都是内部接口，大模型是无法得到内部接口所需的参数的，比如东财，内部接口是需要使用股票代码的，让大模型给出股票代码是不可靠的，大模型是知识是落后的，比如360是变更过代码的，大模型可能无法给出新代码，或者有新上市的股票，也是无法给出代码。解决方法是让大模型拆分任务时，对问句进行改写，再由内部提供的能力（实体识别），对大模型改写后的问句进行识别，获得股票代码。查数据时的指标也是同理，每个指标在报表中是由固定的代码的，大模型无法知道这些代码，需要内部的实体识别接口进行识别。
5. 执行策略：使用注册模式对各个工具进行管理，在解析agent输出后，根据agent的编排，依次动态调取对应工具，执行任务，获取结果输出给用户，并缓存到最终总结任务前，转换格式输入总结模型总结。且为了提升用户体验，优化响应速度，模型中间的查询结果通过SSE分段输出给用户，比如查数据，选股的结果，通过行情图，表格的形式提前展示。deepseek出现后，可以输出思考过程。此外要对执行流程内的所有工具加超时时间，异常处理，防止某一步任务出错导致整个流程阻塞；
6. 记忆和多轮能力：给大模型提供对话的上下文，每一轮问答，agent模型的输入输出都进入缓存，且为了上下文数据的完整性，给agent输入的上下文不仅是agent任务拆分的历史记录，也要把最后的总结输出作为上下文，比如上一轮是选股任务，今天哪些股票涨停了，agent的输出只会是拆分出了选股任务，如果这一轮问他们的股价分别是多少，只有上一轮agent问答记录的话，本轮是不知道去查哪些股票的，因此要把上一轮的回答也作为上下文输入。并且我们还为历史记录添加了一个实体列表字段，记录上一轮识别出的实体，在构建prompt时，给agent模型提供上下文信息。同时用户的问题和回答也记录缓存，本轮输入时，携带最近30分钟的问答的记录作为上下文，但有token限制，过多的会截取。提升agent的多轮对话能力。
7. 降级：上述说过解析可能错误，也可能有超时的情况，程序内部设置错误重试次数，只会试一次，防止多次调用agent导致响应时间过长。两次重试失败后，会走降级逻辑，rag系统搜索相关的信息，比如新闻，再由模型进行总结。

## 模型结果的评价和调优

* 在工程侧，主要关注一些指标：比如输出格式校验，响应速度，触发敏感词；
* 同时要进行记录，出现问题的记录要落库保存，作为给算法团队的反馈，持续优化模型；
* 工程侧对用户，对用户提供反馈功能，反馈结果也要进行分析，并且提供给算法团队；
* 工程侧对数据记录，如我们项目中的所有记录都会异步同步到clickhouse数据库中，可以在clickhouse内进行统计分析，比如用户的暂停生成率，重新生成率，一定程度反映了用户对答案的满意程度。
* 开发和测试有标准问句集，会使用标准问句集在开发自测或正式测试时对模型进行评估，标准问句必须全部无误才能通过。

## prompt设计和调优

1. 身份设定：你是东方财富公司研发的金融大模型，你的名字叫妙想，你可以帮助用户实现行情查询、资讯浏览、社区交流和数据支持等功能。
2. 任务结构化：提供工具信息，分步骤，模块化描述复杂信息：如按以下步骤执行...。
3. 输出约束：明确指定输出的格式，如JSON，markdown；明确指定长度，如输出不得超过200字。
4. 提供样例：如agent任务拆分，prompt中提供多条样例。
5. 配置平台，产品可修改prompt，可以实时更新；

## 大模型参数优化

* temperature：调整大模型的输出分布，值越小，输出越确定，值越大，输出越随机
* top-p：累积概率采样，选择候选，值越大，输出多样性越高，值越小，输出确定性越高
* top-k：选择概率最高的k个值作为候选，值越大，输出多样性越高，值越小，输出确定性越高
* 优先单独调试temperature，top-k和top-p一般通常二选一调整，我们的agent模型设置值都是偏小的，为了保证输出的稳定性。

## 大模型transformer架构

* 两大部分组成，encoder和decoder，encoder把输入转化为固定长度的向量，过程捕捉了输入的特征信息，上下文信息。encoder的输出是decoder的输入，decoder对encoder的输出进行计算，输出结果；
* encoder内分为自注意力层和前馈神经网络子层，decoder内为自注意力层、前馈神经网络子层和encoder-decoder注意力层。

## rag：

* embedding用的是bge
* 把文本切chunk，再embbedding向量化，保存到向量数据库
* 把用户问题向量化，从向量数据库搜索相近的chunk
* 对搜索到的chunk进行重排，选出最相近的topK个chunk
* 输入大模型，大模型回答

## 内存泄漏

* clickhouse连接未释放，导致内存持续增加，触发报警，clickhouse的默认最大连接数量好像是4096；

* dump分析：用jprofile，后面发现idea的ultimate版也有分析功能，发现是connecttion对象很多；
* 在机器上先jps找到pid，再netstat查看连接，发现很多未释放的连接
* 最后查看代码，是clickhouse的connection没有close，因为一直使用spring提供的template，没有管理连接的意识；

## kafka数据堆积

* 线上kafka只有一个partition，但是有六台机器
* 线上缓解，先找运维给kafka增加partition；
* 后期优化，服务内开启批量消费，多线程处理

## CPU打满

* 死循环：查代码，jstack，转十六进制，while循环
* 死锁：jstack查线程情况

## SSE

* 长链接，服务端向客户端单向推送：
* 接口type改成text/event-stream，一般是application/json；
* 返回给前端的数据格式不同，消息以每条发送，三个字段：data（主要，以json字符串为主，需要指定media type为application/json），id（给前端标识顺序），event（事件类型，正常或错误，message/error）；
* 天生异步性，先将SseEmmiter返回给前端，前端才能从eventSource中获取数据；
* 由于前端eventSource仅支持get请求，后端也只能提供get请求；
* 前端主动断开：首先流是否输出完是由后端控制的，正常情况下前端不会主动断开关闭流；但是前端可能发生不可控的断开情况，如用户切换房间，关闭浏览器，杀掉app进程等等，这时后端还向已关闭的连接发送消息，会产生IOexception，catch到SSE的异常，断开输出流，保存历史记录；
* 如果有前端主动断开的情况，即前端调用了eventSource.close，后端也有onCompletion回调，在回调中释放资源；
* 一定要把完成的emmiter complete关闭，否则会产生内存泄漏，为了兜底会在最外层的try catch finally里加入关闭逻辑；

## EventSourceListener：

* okhttp内的SSE接收类，用于调用大模型时接收流式数据：
* 继承EventSourceListener，重写onEvent接口；
* 子类中维护一个列表，每次onEvent触发，把获得的数据加入列表；
* 自定义接收类处理列表中的数据，在处理时攒批次，用标点符号做分隔；
* 主流程持续轮询请求接收类的数据，获取到一个句子，通过SSE发送给前端；
* 为什么要攒批次，主要是因为敏感词过滤，大模型按token输出，可能要多个token才会构成一个敏感词，如果每次模型的输出都去过敏感词，可能会漏掉，同时这样也能减少调用敏感词接口的次数（付费，性能）；

## 项目遇到的问题

* 历史记录只有问题没有答案：用户在模式持续输出时，切换会话，或者关闭浏览器等操作，后端还没有输出完成，这时无法保存历史记录，导致前端显示只有问题没有答案；解决方式：发现前端上述操作会造成IOException，因为在处理流时增加对IOException的捕获，保存当前已输出的答案。
* 还有特殊情况，就是在提问后快速切换，在还没有任务输出的时候就切换频道或者关闭会话，这时没有答案生成，于是无法保存答案。解决方式是在catch exception时判断是否已生成答案，没有则填充固定话术。但也会比较奇怪，如果用户切一个频道，又回来，还要重新提问，于是前端新增了逻辑，如果最后一条对话，只有问题，没有答案，前端自动发起一次提问。
* 还是可能会卡bug，因为我们是三端同步，如果同时在两个端提问，再快速切走，这样可能会导致两个问题连在一起，但没有答案，前端只会给最后一条重新提问。这种还加了兜底逻辑，如果查询历史记录的过程中，出现查问题但没有答案的现象，这条记录不显示；
* 历史记录暂停生成：上述还是无法保证暂停生成时和前端输出的答案完全相同，会出现我暂停时只输出了100个字，切个会话回来，多出来20个字，最终是用前端回传来解决的。
* 历史记录防止大key，zset里最多5000条，超过的不存Redis；
* ==clickhouse连接多没有释放，导致内存溢出==；

## 短链系统实现

* 更普遍的是整个http链接是短链，通过重定向指向对应的长链（302）
* 为什么不用301，因为301是永久重定向，浏览器会缓存对应的长链，如果再次请求，服务端就拿不到短链了（比如想对短链做统计）；
* 先对长链进行哈希Murmurhash，生成32位的哈希值，再将其转换为62进制，就可以得到短链；
* Murmurhash，相比MD5更快，离散度高，分布均匀；
* 把短链和长链的对应关系维护在数据库和缓存中；
* ==怎么实现百亿短链不重复==

## 实际项目中的短链实现

* 没有使用重定向的方式。用户分享需要前端先请求服务端，拿到服务端生成的短链，作为参数，用户点击链接后，服务端解析这个参数，返回对应的历史记录；
* 服务端提供两个接口：获取短链接口，和分享接口。用户点击分享后，前端先请求服务端，传入必要的参数，拿到服务端生成的短链。再将短链作为分享接口的参数生成用户分享出去的链接，被分享的用户点击链接后，服务端拿到短链，从缓存中取出对应的参数，返回分享的历史记录；
* 在长链短链对应中，可以用哈希函数生成一段ID，但是分享历史记录是多个参数，无法用哈希，因此使用了雪花ID作为唯一值（64位），雪花ID生成的数字是十进制，再使用BASE62转换为62进制，就可以得到短链；BASE64有+，在URL中需要转义；
* 如果是长链到短链的转化，用hash可以保证同一个链接多个请求获得的短链是相同的，但是用雪花ID的方法，每次都是不同的ID，这也要看业务需求确定，在我们的项目中，每次分享生成的短链不同并不影响，用户很少关心短链到底是什么。

* 雪花算法：可以用数据库，比如MySQL的自增id，或者MongoDB的objectId，但是要利用数据库，性能要求达不到；Redis也可以用incr获取id，但是也很少用；常用的是雪花算法，但雪花算法有时钟回拨的问题，我们项目中实际使用的是梨花算法，是雪花算法的改进，把雪花算法中毫秒的部分改为了秒，并且有时间容错，避免了时间回拨的问题。此外也有美团的leaf和百度的generate，但都需要额外的服务。

## AOP的使用

* 日志：接口日志，around，记录入参和出参
* 分布式锁：自定义方法注解，aop切到带有注解的方法；

## ES输入提示

* 写入的词有全称，别名，股票代码，拼音首字母，拼音全拼；
* 每天刷新，索引名称中包含日期，因此定义了别名，每天刷新完成后需要把最新的索引挂上别名，搜索时只会搜索别名。这种方式在回退或切换版本时也很方便；
* 用户的输入，有大数据团队提供的分词器，针对金融行业优化的，先用这个分词器分词；
* 然后用分出的词都去ES内搜索，同时也用用户的原句进行搜索；
* 先用prefix严格匹配keyword字段，不分词，匹配前缀；如果数量不够，再用matchPhrasePrefix匹配文本字段，分词，相对不那么精确，也因此能匹配到更多结果；
* slop搜索：slop是match phrase的参数，用于控制查询词项之间的位置偏移容忍度，但是也不能过大，过大会使查询结果偏离太多，对性能也有影响，最多5；
  * 允许词项不严格按顺序出现，如 ABC，bac，slop=2；
  * 允许词项中插入其他词，如AC，ABC，slop=1；



* 项目中屏蔽词，敏感词过滤：用的是DFA算法确定有穷自动机，实现的Trie树。检查时是遍历文本字符，去匹配前缀树的字符，最大时间复杂度是文本的长度。

## 为什么选clickhouse：

* 储存的主体是日志，研究了日志方案，有很多大厂用clickhouse储存日志；
* 大数据量：clickhouse可以容纳大数据量，集群架构支持动态扩缩容；
* 写入性能高：clickhouse写入有很高的吞吐，几乎没有写入瓶颈（建议批量写入），日志的量每日平均4000W，市场好时可到8000W甚至上亿；
* 查询性能：列式储存，数据分区，支持索引（索引巧妙），查询效率高；
* 储存成本：列式储存，压缩率更高，且相比ES对内存要求低；

## nacos

* nacos实现动态更新的原理：长轮询机制，nacos客户端也就是java程序，会对nacos发起长轮询，比较配置是否发生了变化，长轮询是指如果没有更新，服务器会保持连接不响应，直到有配置变更或者超时，请求才结束，这样可以有效减少网络请求次数，提高效率；
* 如果配置发生了变更，nacos服务器会推送给所有订阅了的配置的客户端；
* 想要动态刷新配置，要用@RefreshScope，实际使用是把所有需要动态刷新的配置放在一个类中，给一个类加注解。分散加注解不好管理且可能对性能有影响；
* nacos部署高可用集群，数据库必须MySQL，且需要nginx代理； 

## 使用ConcurrentHashMap的场景：

* agent任务注册的map
* Prometheus的counter，time，gauge都是用的ConcurrentHashMap；



* Redis pipeline，在资讯接口flink那里用到，主要是节省网络开销，优化性能；
* 发布逻辑：灰度，蓝绿等等
* 日志组件：一周所有项目排除log4j，全部使用logback；
* 线上多版本接口兼容
* git回退；
* 分布式事务；


# 系统设计

## 分布式系统的CAP

* C是指一致性：指分布式内的节点，数据是否一致，这里的一致是强一致性，数据修改后，同一时刻每个节点的数据必须完全一致；

* A是指可用性：指分布式整个系统任何时刻都可以提供服务，也就是高可用，通常用概率来衡量，如99.9999

* P是指分区容错性：指分布式系统在某个节点或网络分区故障时，整个系统仍然可以对外提供服务

* 首先**P是一定要满足的**，没有P要不就是只有单个节点，要不就是多个节点，但是任意一个节点故障，整个系统都不可用，实际效果和单个节点没有区别；

* 为什么**AC只能满足一个**：当修改某分布式系统的数据时，无法做到同一时刻修改全部节点，一定有延迟。为了保证A，每个节点都要对外提供服务，但是如果某个节点的数据改动了，但是请求去了另一个节点，就无法取到改动后的节点，就无法满足数据一致性；而如果要满足C，那某个节点的数据改动后，必须要等到所有节点都同步到这个数据才能对外提供服务，必然导致服务的暂定，不满足可用性。因此在保证P的前提下，AC只能满足一个；

* 满足CP：当一个分布式系统一定要强一致性时，比如可以容忍服务停机，也必须保证数据一致，可以选择CP。zookeeper就是CP系统，MongoDB也是CP系统，当主节点故障后，需要选取一个新主节点，写入不可用，副本集保证强一致性；

* 满足AP：牺牲一定的一致性，保证高可用，这是比较常用的系统设计，但是并不是不保证一致性，而是保证数据的最终一致性，允许在一段时间内，分布式节点之间的数据完成同步。高并发的系统一般采用AP，如Redis cluster是AP系统，主从之间的数据同步是异步的，也就是说有延迟，所以可能会造成主节点挂掉，从节点有数据没有同步到的问题，也因为这个，产生了redlock；

## 分布式事务

在一个功能中，需要操作多个库表，要保证这些库表的事务性。比如用户下单商品，需要在订单表中创建一个新数据，也要从库存表中修改商品的数量，需要保证这两个操作一定同时成功或者失败；

* 分布式事务的分类：分为刚性事务和柔性事务，刚性事务满足CP，支持强一致性，支持回滚，隔离性，但性能较低，有如2PC，3PC协议等。柔性事务满足AP，BASE理论，允许中间状态，有如补偿型，异步确认型，最大努力通知型等。

* 两阶段提交（2PC）/ 三阶段提交（3PC）：seata开源的分布式事务解决方案；阶段1，协调者向所有参与者发送事务操作请求，每个参与者进行响应，执行事务操作，并记录redo和undolog，然后向协调者返回响应，执行是否成功；阶段二，协调者根据参与者的返回，判断是提交事务还是回滚事务；
* 异步MQ事务：通过MQ的半消息机制，实现投递消息和参与者本地消息的一致性；1. 先发送半消息到MQ；2. 执行本地事务；3. 根据本地事务的执行结果判断MQ是否提交；4. 如果成功，MQ提交，消费者来消费这个消息，开始执行本地事务；5. 消费者执行本地事务成功，标记该条消息已消费；6. 如果消费者失败，可以重试，如果一直失败，通过补偿机制保证和生产端的最终一致性；
* 本地消息表方案：在数据库新增另一个事务表，用事务表来保证生产者事务和发送消息的一致性，对消息队列的要求降低，但是数据库的读写性能不高，高并发下有性能瓶颈；
* TCC补偿型：使用一个主业务服务，调用从业务服务，每个从业务服务都要实现try，confirm，cancel接口，由主业务服务控制事务的提交和回滚。和2PC的区别是，TCC是业务层面的事务，满足最终一致性，不持有锁；2PC是资源层面的事务，基于数据库实现，每个过程都要对相关数据加锁，高并发情况下会比较差；
* SAGA：长活事务；

## 如何解决分布式事务问题

* 强一致性场景：可以使用seata的AT模式，是增强版的2PC模型，保障强一致性，支持跨多个库修改数据
* 弱一致性场景：可以使用异步MQ事务，如rocketMq，如果消费者失败了，可以使用死信队列作为兜底，用人工或者或定时任务处理；

## 数据库和缓存一致性：

* 旁路模式（cache aside）：读时先查缓存，不存在时查数据库，并回写缓存。写时写数据库，删除缓存，延时一段时间后，再次删除缓存，防止并发时，有穿透读取把旧值写入了缓存（延时双删）；旁路缓存适合读多写少的场景，保证最终一致性，但可能出现短暂的不一致；
* 穿透模式（read through）：读时先查缓存，不存在时查数据库，并回写缓存。写时既写数据库，也写缓存；
* 回写模式（write behind）：写时只写缓存，异步写入数据库，比如通过kafka；
* 实际项目中采用的是穿透模式，且主要保证数据库的正确性，即先写数据库，再写Redis。当然穿透模式是要担心第二步失败的问题，无法在项目中做到原子性；但在我们这个项目中考虑的情况，主要保证Redis内列表的正确性，有会话内所有问题的列表，问题的所有答案的列表，如果列表内存在，但去取单独的key失败，兜底回去MongoDB再查一遍，如果MongoDB也没有就直接丢掉，不会给用户展示时出现问题；如果先写MongoDB，Redis内写失败的话，可能用户先看没有这条记录，但等Redis内失效，从MongoDB读取后，又多出一条记录，这就不能接受了。
* 同时也考虑了回写模式，本来就是要保证Redis内的准确性，可以对MongoDB采用回写模式，但是这又额外需要kafka和一个单独的消费程序，就没有实际使用。

## 秒杀系统

* 高可用：多台服务器
* 缓存：热点数据多级缓存，可以内存里用guava或caffeine缓存一份，Redis也缓存一份
* 库存扣减：下单减库存，超时未支付释放库存。库存量提前放到分布式缓存比如Redis，通过lua脚本，保证操作的原子性，可以避免加锁的开销，Redis是单线程。数据库内可以有延迟，可以定时同步，也可以发送到kafka异步处理；
* 接口高性能：选择限流或削峰。可以使用Redis做分布式限流，也有sentinel可以用，但是要搭配合适的话术；或者削峰，用kafka等消息队列，把请求先发送到队列里，然后服务端从队列里消费处理，但是异步需要用户等待，实现也相对复杂，需要前端定时轮询查询结果，或者用websocket，SSE；
* 考虑降级，熔断，根据实际需求内的逻辑处理；



* 日志，监控，压测
* 账户扣减：每个订单生成唯一ID，如果同一订单重复支付，可以通过ID去重。同一账户不同订单，要对账户加分布式锁，保证扣减操作是串行的，防止扣减错误；
* ==一人一单，超卖，乐观锁，分布式锁，lua脚本==

* 保证接口的安全
  * 鉴权：如果是有登录的，接口调用先检查登录信息。如果没有登录的，比如短信，适用验证码，或者滑块等方式；
  * 限流：可以对ID，手机号或者IP限流；
  * 签名：客服端和服务端约定加密算法，客户端发送的请求都要带签名，对性能有一定影响；
  * 监控：监控一定要做的；
* 点赞
* 评论
  * 至少三张表：评论信息表（ID，点赞数，评论数）
* 过期未支付怎么实现自动关单；
* 分布式事务
* 数据迁移


# 小程序

* 被接口注入
* 数据库数据被删
