# kafka要点

* **kafka保证消息顺序**
  * 生产者如果是多线程发送，可能会产生乱序；如果有重试机制，可能前一条消息重试时，后面的消息先发送；
  * 生产者和消费者都会有的因素：kafka只保证分区内消息的有序，不保证全局的有序，因此如果topic多分区，不同分区间消息的顺序无法保证；
  * 解决方式：如果是严格按照顺序的服务，所有消息都使用单分区，生产者发送使用单线程；
  * 想在多分区的topic里保证顺序，发送时指定partition，或者指定key，相同的key一定会进入同一个partition；
  
* **kafka保证消息不丢失**
  * **生产者**可以给发送消息添加回调函数，添加发送失败时的处理逻辑，重新发送。并且kafka的producer可以设置重试次数，一般可以设为3次，如果是一定不能丢失的消息，可以设置的再高一点。间隔时间不能太小，否则如果一次网络波动，期间完成了所有的重试，消息还是会丢失；

  * **消费者**丢失消息主要是和offset有关，可能在处理消息时宕机了，但是offset已经提交，重启后已经跳过了之前的消息。这种情况可以手动提交offset，在消息处理完成后再提交offset。但这样可能造成重复处理，当数据处理完但offset还没提交时宕机，重启后会再消费一次之前的数据，这就要看服务的需求，哪种情况是可以接受的。

  * kafka集群可能丢失消息：当开启副本机制后，副本的同步是有延迟的，如果副本还没有同步完成，leader就宕机了，那选取新的leader后，就丢失了消息。kafka集群设置ack=all，被所有副本接收后才算消息发送成功，对性能有影响，默认是1，也就是leader成功就算成功；**min.insync.replicas**，消息最少写入的副本数，设置大于1,。

* **kafka保证消息不重复消费**
  * 已经消费成功但没有提交offset，保证消费的幂等性，重复消费没有影响；或者维护一个已消费表，处理前先验证状态（不现实）；

  * kafka消费处理时间长或网络波动导致kafka认为服务假死。触发rebalance；

  * 可以拉到消息就提交，有个定时任务消费兜底；
  
* 幂等性：**一个操作无论执行多少次，结果都与执行一次相同**。

* 多个分区单一消费者时，每次poll，kafka会轮询从各个分区获取数据，尽可能均匀分配拉取批次；

* kafka集群，分区和副本
  * 集群中的kafka实例叫broker，每个集群由多个broker组成；
  * topic可以有多个partition，在集群中，一个topic的partition会分配在多个broker上，保证负载均衡；
  * 每个partition可以有多个副本，partition的副本会分散在不同的broker上，所以在一定的情况下，一个broker可以有一个topic的所有partition；
  * ISR机制：每个partition的leader都会维护一份ISR列表，是和自己保持同步的副本，关闭unclean.leader，当leader挂掉之后，只会从ISR的副本中选举新的leader，保证了消息的不丢失，但会牺牲一定的高可用性；

* kafka的isr机制： **ISR（In-Sync Replicas，同步副本集）机制** 是确保数据高可用性和一致性的核心设计。ISR 是由 **Leader 副本**和与其保持数据同步的 **Follower 副本**组成的动态集合
  * 若生产者设置 `acks=all`，需等待所有 ISR 副本确认写入，Leader 才会提交消息，可以通过参数控制，通过场景的需要设置；
  * Leader 持续监控 Follower 的同步进度，若 Follower 的 LEO 落后超过阈值，将其移出 ISR；恢复同步后重新加入
  * Leader 故障时从 ISR 中选举新 Leader（通常选择 LEO 最大的副本），避免数据不一致
  * Follower 故障：恢复后截断 HW 之后的日志（数据可能不一致），重新从 Leader 同步

* kafka主副之间的同步：
  * 生产者将消息发送到分区的 Leader 副本，Leader 将消息追加到本地日志文件（Log Segment）中，并更新 **LEO（Log End Offset，日志末端位移）**

  * Follower 副本通过后台线程 **ReplicaFetcherThread** 定期向 Leader 发送 **Fetch 请求**，请求从当前 LEO 开始拉取新数据

  * Follower 将拉取到的消息写入本地日志文件，并更新自身的 LEO

  * Leader 在收到 **所有 ISR 副本的 ACK** 后，将 HW 更新为 ISR 中所有副本 LEO 的最小值

  * HW即是以提交的数据，对消费者可见的数据；

  * Leader 使用 `sendfile` 系统调用直接将数据从磁盘页缓存（Page Cache）传输到网络 Socket，减少内存拷贝和上下文切换

* kafka保证消息可靠性
  * 集群，多副本机制，高可用

  * ISR机制

  * ACK机制

  * 持久化：消息写入磁盘，即使宕机，消息也不回丢失

* zookeeper保存kafka的元数据，比如broker的节点信息，topic的信息，topic的partition的信息，也负责kafka的负载均衡等。3.3版本后，kafka提供了kraft模式，不再需要依赖ZK；

* kafka高吞吐量的原因：
  * 顺序IO：kafka的数据是append only，追加到末尾的，数据在磁盘上顺序排列，相比随机IO更快；
  * 分区：kafka一个topic可以设置多个分区，每个分区又可以分别由消费者消费，这样一个topic就有多个消费者并行消费，提升吞吐量；
  * 批处理：生产者可以批量发送，消费者也可以批量消费，减少IO次数；
  * NIO：broker使用NIO处理连接，单线程管理多并发请求，减少线程切换开销；
  * 压缩；
  * 零拷贝

* kafka和其他消息队列的对比，和rocketMq最主要的区别在于对事务的支持
  * **Kafka**：适用大数据处理，日志，流处理等场景，强调高吞吐量和可扩展性
    * 海量数据吞吐能力，支持实时流处理与离线分析
    * 数据持久化与多副本机制，保障高可用性
    * 配置复杂，依赖 ZooKeeper，资源消耗大
    * 不支持事务消息，需结合外部系统实现
  * **RocketMQ**：适用高并发，需要事务的场景
    * 兼顾高吞吐与事务支持，适合金融场景
    * 客户端语言支持有限（主要 Java）
    * 堆积能力较低，功能复杂度较高，学习曲线陡峭
  * **RabbitMQ**、：需要灵活路由，多种消息模型；**ActiveMQ**
    * 吞吐量低，性能低，集群扩展性差

* **RocketMQ**的事务
  * **第一阶段：发送半消息（Half Message）**：生产者向 Broker 发送一条 **半消息**，此时消息对消费者不可见，仅存储在 RocketMQ 的内部队列（如 `RMQ_SYS_TRANS_HALF_TOPIC`）中。若发送失败，事务直接回滚
  * **第二阶段：执行本地事务并提交/回滚**：生产者执行本地事务（如数据库操作），根据结果向 Broker 发送 **Commit** 或 **Rollback** 指令。**Commit**：半消息转移至真实 Topic，消费者可见并消费。**Rollback**：删除半消息，事务终止。
  * 电商下单场景中，订单服务发送“扣减库存”半消息，若本地订单创建成功则提交 Commit，库存服务消费消息扣减库存。